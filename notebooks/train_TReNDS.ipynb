{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ND0y3lqv0UDX"
   },
   "outputs": [],
   "source": [
    "## Lines for Google Colab to import Drive repository and configure GitHub\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "%cd /content/gdrive/My Drive/capita_selecta_cvbm/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jMuWtcXTZrwG"
   },
   "outputs": [],
   "source": [
    "## Lines for Google Colab to push and pull form GitHub repository\n",
    "# %cd /content/gdrive/My Drive/capita_selecta_cvbm\n",
    "# !git pull origin master\n",
    "\n",
    "# !git remote rm origin\n",
    "# !git remote add origin https://Beerend:XXXXX@github.com/Beerend/TReNDS.git\n",
    "\n",
    "# !git pull origin master\n",
    "# !git status\n",
    "# !git add train_TReNDS.ipynb\n",
    "# !git commit -m 'Added MAE loss'\n",
    "# !git push origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 552,
     "status": "ok",
     "timestamp": 1598000755053,
     "user": {
      "displayName": "Beerend Gerats",
      "photoUrl": "",
      "userId": "02409374618171011835"
     },
     "user_tz": -120
    },
    "id": "oNvdaMeg0UDe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import MSELoss, L1Loss\n",
    "from datasets import TReNDS\n",
    "from datasets.TReNDS import TReNDSDataset\n",
    "from models import resnet, deeplight, resnet_4d\n",
    "# from google.colab import output\n",
    "from importlib import reload\n",
    "\n",
    "# reload(TReNDS)\n",
    "reload(resnet)\n",
    "# from datasets.TReNDS import TReNDSDataset\n",
    "from models import resnet\n",
    "\n",
    "\n",
    "#ResNet3D is from SeuTao (https://github.com/SeuTao/RSNA2019_Intracranial-Hemorrhage-Detection/tree/bbdb1e1d645953ef4b2f23c87b6fba44aff023ea/3DNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 535,
     "status": "ok",
     "timestamp": 1598000769195,
     "user": {
      "displayName": "Beerend Gerats",
      "photoUrl": "",
      "userId": "02409374618171011835"
     },
     "user_tz": -120
    },
    "id": "LBZWToNW0UDi"
   },
   "outputs": [],
   "source": [
    "# Home PC\n",
    "data_path = '/Volumes/External Hard Drive/Documents/University of Twente/Computer Science/Capita Selecta'\n",
    "root = '../'\n",
    "\n",
    "# Google Colab\n",
    "# data_path = '/content/gdrive/My Drive/capita_selecta_cvbm'\n",
    "# root = '/content/gdrive/My Drive/capita_selecta_cvbm'\n",
    "\n",
    "available_models = ['deeplight',\n",
    "                    'deeplight_tempframe_26',\n",
    "                    'deeplight_resnet10',\n",
    "                    'resnet10',\n",
    "                    'resnet10_4d']\n",
    "\n",
    "model_name = 'resnet10'\n",
    "fold_index = 0\n",
    "\n",
    "# Options\n",
    "opts = {\n",
    "    'rand_seed'  : 1,\n",
    "    'no_cuda'    : True,\n",
    "    'temp_mean'  : False,\n",
    "    'preprocess' : False,\n",
    "    'scale_norm' : False,\n",
    "    'lr'         : 1e-4,\n",
    "    'train_bs'   : 1,\n",
    "    'test_bs'    : 1,\n",
    "    'epochs'     : 1,\n",
    "    'fold_index' : fold_index,\n",
    "    'n_splits'   : 5,\n",
    "    'model_name' : model_name,\n",
    "    'save_at_eps': list(range(1,61)),\n",
    "    'test_at_eps': list(range(1,61)),\n",
    "    'save_dir'   : os.path.join(root, 'results/%s/%s'%(model_name, str(fold_index))),\n",
    "    'resume'     : None, #os.path.join(root, 'results/deeplight/0/epoch_5.pth.tar'),\n",
    "    'pretrain'   : None,\n",
    "}\n",
    "\n",
    "if not os.path.exists(opts['save_dir']):\n",
    "    os.makedirs(opts['save_dir'])\n",
    "    \n",
    "torch.manual_seed(opts['rand_seed'])\n",
    "earlier_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 600,
     "status": "ok",
     "timestamp": 1598000876474,
     "user": {
      "displayName": "Beerend Gerats",
      "photoUrl": "",
      "userId": "02409374618171011835"
     },
     "user_tz": -120
    },
    "id": "5Zy2uvBJ0UDn",
    "outputId": "87ea2ce9-15c7-47bd-9a78-b4a4c1902d02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded resnet10 (param: 15497537, trainable: 15497537, GPU: False)\n"
     ]
    }
   ],
   "source": [
    "# Generate model\n",
    "assert model_name in available_models\n",
    "if model_name=='deeplight':\n",
    "    model = deeplight.original()\n",
    "elif model_name=='deeplight_tempframe_26':\n",
    "    model = deeplight.original(temp_frame=26)\n",
    "elif model_name=='resnet10':\n",
    "    model = resnet.resnet10(shortcut_type='B', no_cuda=opts['no_cuda'], num_class=1)\n",
    "elif model_name=='resnet10_4d':\n",
    "    model = resnet_4d.resnet10_4d(shortcut_type='B', no_cuda=opts['no_cuda'], num_class=1)\n",
    "    \n",
    "optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=opts['lr']) #, betas=(.9,.999), eps=1e-08)\n",
    "mse   = MSELoss()\n",
    "mae   = L1Loss()\n",
    "\n",
    "if not opts['no_cuda']:\n",
    "    model.cuda()\n",
    "    \n",
    "num_params    = sum(p.numel() for p in model.parameters())\n",
    "num_tr_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('Loaded %s (param: %d, trainable: %d, GPU: %s)'%(model_name, num_params, num_tr_params, not opts['no_cuda']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 536,
     "status": "ok",
     "timestamp": 1597997706532,
     "user": {
      "displayName": "Beerend Gerats",
      "photoUrl": "",
      "userId": "02409374618171011835"
     },
     "user_tz": -120
    },
    "id": "tYO27GM00UDq",
    "outputId": "f41c30a0-816e-43fc-e016-e140055452e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from: /content/gdrive/My Drive/capita_selecta_cvbm/results/deeplight/0/epoch_5.pth.tar\n"
     ]
    }
   ],
   "source": [
    "# Train from checkpoint\n",
    "if opts['resume']:\n",
    "    if os.path.isfile(opts['resume']):\n",
    "        print('Loading checkpoint from:', opts['resume'])\n",
    "        load_dict = torch.load(opts['resume']) #, map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(load_dict['state_dict'])\n",
    "        optim.load_state_dict(load_dict['optim'])\n",
    "        earlier_epochs = load_dict['epoch']\n",
    "        \n",
    "# Train from pre-trained model\n",
    "elif opts['pretrain']:\n",
    "    if os.path.isfile(opts['pretrain']):\n",
    "        print('Loading pre-trained weights from:', opts['pretrain'])\n",
    "        model_dict = model.state_dict()\n",
    "        pretrain   = torch.load(opts['pretrain'])\n",
    "        pretr_dict = {k:v for k,v in pretrain['state_dict'].items() if k in model_dict.keys() and 'conv1' not in k}\n",
    "        model_dict.update(pretr_dict)\n",
    "        model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 692,
     "status": "ok",
     "timestamp": 1598000884577,
     "user": {
      "displayName": "Beerend Gerats",
      "photoUrl": "",
      "userId": "02409374618171011835"
     },
     "user_tz": -120
    },
    "id": "cqnxLn770UDv",
    "outputId": "cf6f797f-e4a8-4a75-8eb6-884ed75962bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 4701 train samples in fold 0.\n",
      "Loaded dataset with 1176 test samples in fold 0.\n"
     ]
    }
   ],
   "source": [
    "# Get dataset\n",
    "train_set    = TReNDSDataset(data_path, 'train', n_splits=opts['n_splits'], fold=fold_index,\n",
    "                             preprocess=opts['preprocess'], norm=opts['scale_norm'],\n",
    "                             temp_mean=opts['temp_mean'])\n",
    "train_loader = DataLoader(train_set, batch_size=opts['train_bs'], shuffle=True, pin_memory=True)\n",
    "test_set     = TReNDSDataset(data_path, 'test', n_splits=opts['n_splits'], fold=fold_index,\n",
    "                             preprocess=opts['preprocess'], norm=opts['scale_norm'],\n",
    "                             temp_mean=opts['temp_mean'])\n",
    "test_loader  = DataLoader(test_set, batch_size=opts['test_bs'], shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z43MuHbS0UDy",
    "outputId": "76a53322-17af-476a-f7af-09e904754f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([1, 53, 52, 63, 53])\n",
      "After conv1: torch.Size([1, 64, 26, 32, 27])\n",
      "After maxpool: torch.Size([1, 64, 13, 16, 14])\n",
      "--- shape x: torch.Size([1, 64, 13, 16, 14])\n",
      "--- shape r: torch.Size([1, 64, 13, 16, 14])\n",
      "After layer1: torch.Size([1, 64, 13, 16, 14])\n",
      "--- Downsample residual\n",
      "--- shape x: torch.Size([1, 128, 7, 8, 7])\n",
      "--- shape r: torch.Size([1, 128, 7, 8, 7])\n",
      "After layer2: torch.Size([1, 128, 7, 8, 7])\n",
      "--- Downsample residual\n",
      "--- shape x: torch.Size([1, 256, 7, 8, 7])\n",
      "--- shape r: torch.Size([1, 256, 7, 8, 7])\n",
      "After layer3: torch.Size([1, 256, 7, 8, 7])\n",
      "--- Downsample residual\n",
      "--- shape x: torch.Size([1, 512, 7, 8, 7])\n",
      "--- shape r: torch.Size([1, 512, 7, 8, 7])\n",
      "After layer4: torch.Size([1, 512, 7, 8, 7])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f7d7f526fcdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mmae_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mmse_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mmse_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'deeplight'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "if not opts['resume']:\n",
    "    log_file = open(os.path.join(opts['save_dir'], 'log.txt'), 'w')\n",
    "    log_file.write('Epoch,set,MSE,MAE,time\\n')\n",
    "    log_file.flush()\n",
    "    log_file.close()\n",
    "\n",
    "for epoch in range(1+earlier_epochs, opts['epochs']+1+earlier_epochs):\n",
    "    # TODO: adjust learning rate\n",
    "\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    batches    = len(train_loader)\n",
    "\n",
    "    batch_id = 1\n",
    "    tot_mae  = 0.\n",
    "    tot_mse  = 0.\n",
    "    \n",
    "    for batch_data in train_loader:\n",
    "        imgs, lbls   = batch_data\n",
    "        batch_id_tot = batch_id+(epoch-earlier_epochs-1)*batches\n",
    "\n",
    "        if not opts['no_cuda']:\n",
    "            imgs = imgs.cuda()\n",
    "            lbls = lbls.cuda()\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        preds    = model(imgs)\n",
    "        mae_loss = mae(preds, lbls)\n",
    "        mse_loss = mse(preds, lbls)\n",
    "        mse_loss.backward()\n",
    "        if model_name=='deeplight':\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optim.step()\n",
    "        \n",
    "        avg_batch_time = (time.time()-start_time)/batch_id_tot\n",
    "#         output.clear('batch_inf')\n",
    "#         with output.use_tags('batch_inf'):\n",
    "#             print('Training model => Epoch: %d/%d - batch: %d/%d - loss: %.5f (MSE) %.5f (MAE) - time: %.3f'%(epoch,\n",
    "#                 opts['epochs']+earlier_epochs, batch_id, batches, mse_loss.item(), mae_loss.item(), avg_batch_time))\n",
    "        \n",
    "#         print('Training model => Epoch: %d/%d - batch: %d/%d - loss: %.5f (MSE) %.5f (MAE) - time: %.3f'%(epoch,\n",
    "#             opts['epochs']+earlier_epochs, batch_id, batches, mse_loss.item(), mae_loss.item(), avg_batch_time), end='\\r')\n",
    "        \n",
    "        tot_mae+=mae_loss.item()\n",
    "        tot_mse+=mse_loss.item()\n",
    "        batch_id+=1\n",
    "    \n",
    "    avg_mae  = tot_mae/batches\n",
    "    avg_mse  = tot_mse/batches\n",
    "    tot_time = time.time()-start_time\n",
    "    \n",
    "    log_file = open(os.path.join(opts['save_dir'], 'log.txt'), 'a')\n",
    "    log_file.write('%d,train,%.5f,%.5f,%.1f\\n'%(epoch, avg_mse, avg_mae, tot_time))\n",
    "    log_file.flush()\n",
    "    log_file.close()\n",
    "            \n",
    "    if epoch==opts['epochs'] or epoch in opts['save_at_eps']:\n",
    "        filename = os.path.join(opts['save_dir'], 'epoch_%d.pth.tar'%(epoch))\n",
    "        torch.save({'epoch':epoch, 'state_dict':model.state_dict(),\n",
    "            'optim':optim.state_dict()}, filename)\n",
    "        \n",
    "    if epoch in opts['test_at_eps']:\n",
    "        results = evaluate_model(test_loader, model, mae, mse, epoch, opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1598000889258,
     "user": {
      "displayName": "Beerend Gerats",
      "photoUrl": "",
      "userId": "02409374618171011835"
     },
     "user_tz": -120
    },
    "id": "mVLQf8hDOWiM"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(test_loader, model, mae, mse, epoch, opts):\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    batches    = len(test_loader)\n",
    "    all_preds  = []\n",
    "    all_labls  = []\n",
    "    tot_mae    = 0.\n",
    "    tot_mse    = 0.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_id = 1\n",
    "        for batch_data in test_loader:\n",
    "            imgs, lbls  = batch_data\n",
    "\n",
    "            if not opts['no_cuda']:\n",
    "                imgs = imgs.cuda()\n",
    "                lbls = lbls.cuda()\n",
    "            \n",
    "            preds    = model(imgs)\n",
    "            mae_loss = mae(preds, lbls)\n",
    "            mse_loss = mse(preds, lbls)\n",
    "\n",
    "            output.clear('batch_inf')\n",
    "            with output.use_tags('batch_inf'):\n",
    "                print('Evaluating model => Batch: %d/%d - loss: %.5f (MSE) %.5f (MAE)'%(batch_id,\n",
    "                    batches, mse_loss.item(), mae_loss.item()))\n",
    "            \n",
    "            tot_mae+=mae_loss.item()\n",
    "            tot_mse+=mse_loss.item()\n",
    "            all_preds.append(preds.data.cpu().numpy().flatten())\n",
    "            all_labls.append(lbls.data.cpu().numpy().flatten())\n",
    "            batch_id+=1\n",
    "\n",
    "    avg_mae  = tot_mae/batches\n",
    "    avg_mse  = tot_mse/batches\n",
    "    tot_time = time.time()-start_time\n",
    "    \n",
    "    log_file = open(os.path.join(opts['save_dir'], 'log.txt'), 'a')\n",
    "    log_file.write('%d,test,%.5f,%.5f,%.1f\\n'%(epoch, avg_mse, avg_mae, tot_time))\n",
    "    log_file.flush()\n",
    "    log_file.close()\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labls = np.concatenate(all_labls, axis=0)\n",
    "    filename  = os.path.join(opts['save_dir'], 'preds_epoch_%d.csv'%(epoch))\n",
    "    results   = pd.DataFrame(data={'Pred':all_preds, 'Label':all_labls})\n",
    "    results.to_csv(filename, index=False)\n",
    "\n",
    "    output.clear('batch_inf')\n",
    "    print('Average loss: %.3f (MSE) %.3f (MAE)'%(avg_mae,avg_mse))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1984409,
     "status": "ok",
     "timestamp": 1597999728331,
     "user": {
      "displayName": "Beerend Gerats",
      "photoUrl": "",
      "userId": "02409374618171011835"
     },
     "user_tz": -120
    },
    "id": "LMNYHeCvklXA",
    "outputId": "3e887b9f-fb68-4dd3-eb60-09ddcf965046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 11.102 (MSE) 188.586 (MAE)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.161644</td>\n",
       "      <td>38.617382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.289677</td>\n",
       "      <td>35.326580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.289486</td>\n",
       "      <td>35.326580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.289654</td>\n",
       "      <td>64.203110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.289528</td>\n",
       "      <td>66.532631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>52.289722</td>\n",
       "      <td>57.436077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>52.289742</td>\n",
       "      <td>48.948757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>52.289402</td>\n",
       "      <td>42.941154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>52.289536</td>\n",
       "      <td>14.257265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>52.116913</td>\n",
       "      <td>55.456978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1176 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pred      Label\n",
       "0     52.161644  38.617382\n",
       "1     52.289677  35.326580\n",
       "2     52.289486  35.326580\n",
       "3     52.289654  64.203110\n",
       "4     52.289528  66.532631\n",
       "...         ...        ...\n",
       "1171  52.289722  57.436077\n",
       "1172  52.289742  48.948757\n",
       "1173  52.289402  42.941154\n",
       "1174  52.289536  14.257265\n",
       "1175  52.116913  55.456978\n",
       "\n",
       "[1176 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(test_loader, model, mae, mse, 5, opts)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "train_TReNDS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
