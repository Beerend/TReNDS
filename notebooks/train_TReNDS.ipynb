{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_TReNDS.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"ND0y3lqv0UDX","colab":{}},"source":["## Lines for Google Colab to import Drive repository and configure GitHub\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd /content/gdrive/My Drive/capita_selecta_cvbm/notebooks\n","!pip install nilearn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jMuWtcXTZrwG","colab":{}},"source":["## Lines for Google Colab to push and pull form GitHub repository\n","# %cd /content/gdrive/My Drive/capita_selecta_cvbm\n","# !git pull origin master\n","\n","# !git remote rm origin\n","# !git remote add origin https://Beerend:XXXXX@github.com/Beerend/TReNDS.git\n","\n","# !git pull origin master\n","# !git status\n","# !git add train_TReNDS.ipynb\n","# !git commit -m 'Added MAE loss'\n","# !git push origin master"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oNvdaMeg0UDe","colab":{},"executionInfo":{"status":"ok","timestamp":1598568882819,"user_tz":-120,"elapsed":6615,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}}},"source":["import os\n","import time\n","import numpy as np\n","import pandas as pd\n","import torch\n","from scipy import stats\n","from torch.utils.data import DataLoader\n","from torch.nn import MSELoss, L1Loss\n","from datasets import TReNDS\n","from datasets.TReNDS import TReNDSDataset\n","from models import resnet, deeplight, resnet_4d\n","from google.colab import output\n","from importlib import reload\n","\n","# reload(TReNDS)\n","# reload(resnet_4d)\n","# from datasets.TReNDS import TReNDSDataset\n","# from models import resnet_4d\n","\n","if os.name=='posix': google_colab = True\n","else: google_colab = False"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LBZWToNW0UDi","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598568893503,"user_tz":-120,"elapsed":559,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}},"outputId":"3839527d-9db7-4432-81ff-3d3e7dc3d0ca"},"source":["if google_colab:\n","    print('Working from a Google Colab environment')\n","    data_path = '/content/gdrive/My Drive/capita_selecta_cvbm'\n","    root = '/content/gdrive/My Drive/capita_selecta_cvbm'\n","else:\n","    data_path = '/Volumes/External Hard Drive/Documents/University of Twente/Computer Science/Capita Selecta'\n","    root = '../'\n","\n","available_models = ['deeplight',\n","                    'deeplight_tempframe_26',\n","                    'deeplight_resnet10',\n","                    'resnet10',\n","                    'resnet10_4d']\n","\n","model_name = 'resnet10_4d'\n","fold_index = 1\n","\n","# Options\n","opts = {\n","    'rand_seed'  : 1,\n","    'no_cuda'    : False,\n","    'temp_mean'  : False,\n","    'preprocess' : False, #Adds Â±1.2s per data sample, per epoch on CPU\n","    'scale_norm' : True, #Adds no distinctive additional time to processing\n","    'lr'         : 1e-4,\n","    'train_bs'   : 1,\n","    'test_bs'    : 1,\n","    'epochs'     : 60,\n","    'fold_index' : fold_index,\n","    'n_splits'   : 5,\n","    'model_name' : model_name,\n","    'save_at_eps': list(range(1,61)),\n","    'test_at_eps': list(range(1,61)),\n","    'save_dir'   : os.path.join(root, 'results/%s/%s'%(model_name, str(fold_index))),\n","    'resume'     : os.path.join(root, 'results/resnet10_4d/1/epoch_3.pth.tar'),\n","    'pretrain'   : None,\n","}\n","\n","if not os.path.exists(opts['save_dir']):\n","    os.makedirs(opts['save_dir'])\n","    \n","torch.manual_seed(opts['rand_seed'])\n","earlier_epochs = 0"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Working from a Google Colab environment\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5Zy2uvBJ0UDn","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598568960206,"user_tz":-120,"elapsed":1344,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}},"outputId":"efa0ce3d-f45d-490d-dc4e-45d1fbe280b8"},"source":["# Generate model\n","assert model_name in available_models\n","if model_name=='deeplight':\n","    model = deeplight.original()\n","elif model_name=='deeplight_tempframe_26':\n","    model = deeplight.original(temp_frame=26)\n","elif model_name=='resnet10':\n","    model = resnet.resnet10(shortcut_type='B', no_cuda=opts['no_cuda'], num_class=1)\n","elif model_name=='resnet10_4d':\n","    model = resnet_4d.resnet10_4d(shortcut_type='B', no_cuda=opts['no_cuda'], num_class=1)\n","    \n","optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=opts['lr']) #, betas=(.9,.999), eps=1e-08)\n","mse   = MSELoss()\n","mae   = L1Loss()\n","\n","if not opts['no_cuda']:\n","    model.cuda()\n","    \n","num_params    = sum(p.numel() for p in model.parameters())\n","num_tr_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print('Loaded %s (param: %d, trainable: %d, GPU: %s)'%(model_name, num_params, num_tr_params, not opts['no_cuda']))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Loaded resnet10_4d (param: 42799297, trainable: 42799297, GPU: True)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tYO27GM00UDq","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1598568963801,"user_tz":-120,"elapsed":1273,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}},"outputId":"e33c8515-40bb-4a02-9350-85ff2d405138"},"source":["# Train from checkpoint\n","if opts['resume']:\n","    if os.path.isfile(opts['resume']):\n","        print('Loading checkpoint from:', opts['resume'])\n","        if opts['no_cuda']:\n","          load_dict = torch.load(opts['resume'], map_location=torch.device('cpu'))\n","        else:\n","          load_dict = torch.load(opts['resume'])\n","        model.load_state_dict(load_dict['state_dict'])\n","        optim.load_state_dict(load_dict['optim'])\n","        earlier_epochs = load_dict['epoch']\n","        print('Earlier epochs:', earlier_epochs)\n","        \n","# Train from pre-trained model\n","elif opts['pretrain']:\n","    if os.path.isfile(opts['pretrain']):\n","        print('Loading pre-trained weights from:', opts['pretrain'])\n","        model_dict = model.state_dict()\n","        pretrain   = torch.load(opts['pretrain'])\n","        pretr_dict = {k:v for k,v in pretrain['state_dict'].items() if k in model_dict.keys() and 'conv1' not in k}\n","        model_dict.update(pretr_dict)\n","        model.load_state_dict(model_dict)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Loading checkpoint from: /content/gdrive/My Drive/capita_selecta_cvbm/results/resnet10_4d/1/epoch_3.pth.tar\n","Earlier epochs: 3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cqnxLn770UDv","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1598568968891,"user_tz":-120,"elapsed":555,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}},"outputId":"020d3a5b-3e4b-410b-82a8-34116d044323"},"source":["# Get dataset\n","train_set    = TReNDSDataset(data_path, 'train', n_splits=opts['n_splits'], fold=fold_index,\n","                             preprocess=opts['preprocess'], norm=opts['scale_norm'],\n","                             temp_mean=opts['temp_mean'])\n","train_loader = DataLoader(train_set, batch_size=opts['train_bs'], shuffle=True, pin_memory=True)\n","test_set     = TReNDSDataset(data_path, 'test', n_splits=opts['n_splits'], fold=fold_index,\n","                             preprocess=opts['preprocess'], norm=opts['scale_norm'],\n","                             temp_mean=opts['temp_mean'])\n","test_loader  = DataLoader(test_set, batch_size=opts['test_bs'], shuffle=False, pin_memory=True)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Loaded dataset with 4701 train samples in fold 1.\n","Loaded dataset with 1176 test samples in fold 1.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Z43MuHbS0UDy","colab":{}},"source":["# Train model\n","if not opts['resume']:\n","    log_file = open(os.path.join(opts['save_dir'], 'log.txt'), 'w')\n","    log_file.write('Epoch,set,time,MSE,MAE,Pearson r,p-value\\n')\n","    log_file.flush()\n","    log_file.close()\n","\n","for epoch in range(1+earlier_epochs, opts['epochs']+1+earlier_epochs):\n","    model.train()\n","    # TODO: adjust learning rate\n","    start_time = time.time()\n","    batches    = len(train_loader)\n","    batch_id   = 1\n","    tot_mae    = 0.\n","    tot_mse    = 0.\n","    \n","    for batch_data in train_loader:\n","        imgs, lbls   = batch_data\n","\n","        if not opts['no_cuda']:\n","            imgs = imgs.cuda()\n","            lbls = lbls.cuda()\n","        \n","        optim.zero_grad()\n","        preds    = model(imgs)\n","        mae_loss = mae(preds, lbls)\n","        mse_loss = mse(preds, lbls)\n","        mae_loss.backward() # Optimizing with MAE\n","        if model_name=='deeplight':\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n","        optim.step()\n","        \n","        avg_batch_time = (time.time()-start_time)/batch_id\n","        eta = (batches-batch_id)*avg_batch_time/60\n","        if google_colab:\n","            output.clear('batch_inf')\n","            with output.use_tags('batch_inf'):\n","                print('Training model => Epoch: %d/%d - batch: %d/%d - loss: %.5f (MSE) %.5f (MAE) - time: %.1f (avg) %.1f (ETA in min.)'%(epoch,\n","                    opts['epochs']+earlier_epochs, batch_id, batches, mse_loss.item(), mae_loss.item(), avg_batch_time, eta))\n","        else:\n","            print('Training model => Epoch: %d/%d - batch: %d/%d - loss: %.5f (MSE) %.5f (MAE) - time: %.1f (avg) %.1f (ETA in min.)'%(epoch,\n","                opts['epochs']+earlier_epochs, batch_id, batches, mse_loss.item(), mae_loss.item(), avg_batch_time, eta), end='\\r')\n","        \n","        tot_mae+=mae_loss.item()\n","        tot_mse+=mse_loss.item()\n","        batch_id+=1\n","    \n","    avg_mae  = tot_mae/batches\n","    avg_mse  = tot_mse/batches\n","    tot_time = time.time()-start_time\n","    \n","    log_file = open(os.path.join(opts['save_dir'], 'log.txt'), 'a')\n","    log_file.write('%d,train,%.1f,%.5f,%.5f\\n'%(epoch, tot_time, avg_mse, avg_mae))\n","    log_file.flush()\n","    log_file.close()\n","            \n","    if epoch==opts['epochs'] or epoch in opts['save_at_eps']:\n","        filename = os.path.join(opts['save_dir'], 'epoch_%d.pth.tar'%(epoch))\n","        torch.save({'epoch':epoch, 'state_dict':model.state_dict(),\n","            'optim':optim.state_dict()}, filename)\n","        \n","    if epoch in opts['test_at_eps']:\n","        results = evaluate_model(test_loader, model, mae, mse, epoch, opts)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mVLQf8hDOWiM","colab":{},"executionInfo":{"status":"ok","timestamp":1598568974520,"user_tz":-120,"elapsed":587,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}}},"source":["def evaluate_model(test_loader, model, mae, mse, epoch, opts):\n","    model.eval()\n","    start_time = time.time()\n","    batches    = len(test_loader)\n","    all_preds  = []\n","    all_labls  = []\n","    tot_mae    = 0.\n","    tot_mse    = 0.\n","\n","    with torch.no_grad():\n","        batch_id = 1\n","        for batch_data in test_loader:\n","            imgs, lbls  = batch_data\n","\n","            if not opts['no_cuda']:\n","                imgs = imgs.cuda()\n","                lbls = lbls.cuda()\n","            \n","            preds    = model(imgs)\n","            mae_loss = mae(preds, lbls)\n","            mse_loss = mse(preds, lbls)\n","\n","            avg_batch_time = (time.time()-start_time)/batch_id\n","            eta = (batches-batch_id)*avg_batch_time/60\n","            if google_colab:\n","                output.clear('batch_inf')\n","                with output.use_tags('batch_inf'):\n","                    print('Evaluating model => Batch: %d/%d - loss: %.5f (MSE) %.5f (MAE) - time: %.1f (avg) %.1f (ETA in min.)'%(batch_id,\n","                        batches, mse_loss.item(), mae_loss.item(), avg_batch_time, eta))\n","            \n","            tot_mae+=mae_loss.item()\n","            tot_mse+=mse_loss.item()\n","            all_preds.append(preds.data.cpu().numpy().flatten())\n","            all_labls.append(lbls.data.cpu().numpy().flatten())\n","            batch_id+=1\n","\n","    avg_mae  = tot_mae/batches\n","    avg_mse  = tot_mse/batches\n","    tot_time = time.time()-start_time\n","    \n","    all_preds = np.concatenate(all_preds, axis=0)\n","    all_labls = np.concatenate(all_labls, axis=0)\n","    filename  = os.path.join(opts['save_dir'], 'preds_epoch_%d.csv'%(epoch))\n","    results   = pd.DataFrame(data={'Pred':all_preds, 'Label':all_labls})\n","    results.to_csv(filename, index=False)\n","\n","    r, p = stats.pearsonr(all_preds.tolist(), all_labls.tolist())\n","\n","    log_file = open(os.path.join(opts['save_dir'], 'log.txt'), 'a')\n","    log_file.write('%d,test,%.1f,%.5f,%.5f,%.5f,%.7f\\n'%(epoch, tot_time, avg_mse, avg_mae, r, p))\n","    log_file.flush()\n","    log_file.close()\n","\n","    output.clear('batch_inf')\n","    print('Average loss: %.3f (MSE) %.3f (MAE)'%(avg_mae,avg_mse))\n","\n","    return results"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Edc943R6p1dL","colab_type":"text"},"source":["**Perform an isolated evaluation and print 20 predictions**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LMNYHeCvklXA","colab":{}},"source":["results = evaluate_model(test_loader, model, mae, mse, 2, opts)\n","results.head(20)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5LIA72Pzpf79","colab_type":"text"},"source":["**Calculate losses from predictions csv file**"]},{"cell_type":"code","metadata":{"id":"gy__JhKpENcz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598384008821,"user_tz":-120,"elapsed":480,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}},"outputId":"59866f45-1788-4392-ff17-5a7f66884416"},"source":["results = pd.read_csv('../results/resnet10_4d/0/preds_epoch_2.csv')\n","\n","all_preds = results['Pred'].to_list()\n","all_labls = results['Label'].to_list()\n","\n","mae = 0.\n","mse = 0.\n","for i in range(len(all_preds)):\n","    pred = all_preds[i]\n","    labl = all_labls[i]\n","    mae += np.abs(pred-labl)\n","    mse += (pred-labl)**2\n","\n","mae /= len(all_preds)\n","mse /= len(all_preds)\n","print(mae, mse)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["10.847196312925162 181.8990364785956\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PVcGNAHQpmqP","colab_type":"text"},"source":["**Calculate mean, minimum and maximum values of dataset set**"]},{"cell_type":"code","metadata":{"id":"HD07UmWkpSdW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598465576827,"user_tz":-120,"elapsed":3281233,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}},"outputId":"6672f029-1342-41c7-ba23-25a5f17ce82a"},"source":["mean = 0.0\n","min  = 999.0\n","max  = -999.0\n","\n","batch_id = 1\n","batches  = len(train_loader)\n","for batch_data in train_loader:\n","    assert opts['train_bs']==1\n","    img, lbls = batch_data\n","\n","    img_mean = torch.mean(img).item()\n","    img_min  = torch.min(img).item()\n","    img_max  = torch.max(img).item()\n","\n","    mean+=img_mean\n","\n","    if img_min<min:\n","        min = img_min\n","    if img_max>max:\n","        max = img_max\n","\n","    output.clear('batch_inf')\n","    with output.use_tags('batch_inf'):\n","        print('Calculating => Batch: %d/%d'%(batch_id, batches))\n","    batch_id+=1\n","\n","mean/=batches\n","\n","output.clear('batch_inf')\n","with output.use_tags('batch_inf'):\n","    print('Mean:', mean, 'Min:', min, 'Max:', max, 'Fold:', fold_index)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mean: 0.0513693805085198 Min: -26.703125 Max: 25.53125 Fold: 4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QcIxNEDk-Vqa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1598469414589,"user_tz":-120,"elapsed":3671401,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}},"outputId":"32fe4692-70a4-4833-f2e0-caff0bf184ac"},"source":["mean = 0.0\n","\n","batch_id = 1\n","batches  = len(train_loader)\n","for batch_data in train_loader:\n","    img, lbls = batch_data\n","    img_mean = torch.mean(img).item()\n","    mean+=img_mean\n","\n","    output.clear('batch_inf')\n","    with output.use_tags('batch_inf'):\n","        print('Calculating => Batch: %d/%d'%(batch_id, batches))\n","    batch_id+=1\n","\n","batch_id = 1\n","batches  = len(test_loader)\n","for batch_data in test_loader:\n","    img, lbls = batch_data\n","    img_mean = torch.mean(img).item()\n","    mean+=img_mean\n","    \n","    output.clear('batch_inf')\n","    with output.use_tags('batch_inf'):\n","        print('Calculating => Batch: %d/%d'%(batch_id, batches))\n","    batch_id+=1\n","\n","mean/=(len(train_loader)+len(test_loader))\n","print('Mean:', mean)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Calculating => Batch: 1175/1175\n"],"name":"stdout"},{"output_type":"stream","text":["Mean: 0.051363078512534084\n"],"name":"stdout"}]}]}