{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_TReNDS.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"ND0y3lqv0UDX","colab":{"base_uri":"https://localhost:8080/","height":258},"executionInfo":{"status":"ok","timestamp":1600121315966,"user_tz":-120,"elapsed":28222,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}},"outputId":"7f4cb895-e341-45d6-fc58-159943f0d050"},"source":["## Lines for Google Colab to import Drive repository and configure GitHub\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd /content/gdrive/My Drive/capita_selecta_cvbm/notebooks\n","!pip install nilearn"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/capita_selecta_cvbm/notebooks\n","Collecting nilearn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/c2/f5f1bdd37a3da28b3b34305e4ba27cce468db6073998d62a38abd0e281da/nilearn-0.6.2-py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 8.0MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.6/dist-packages (from nilearn) (1.4.1)\n","Requirement already satisfied: nibabel>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from nilearn) (3.0.2)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from nilearn) (0.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from nilearn) (0.16.0)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from nilearn) (1.18.5)\n","Requirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.6/dist-packages (from nilearn) (0.22.2.post1)\n","Installing collected packages: nilearn\n","Successfully installed nilearn-0.6.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oNvdaMeg0UDe","colab":{},"executionInfo":{"status":"ok","timestamp":1600121437853,"user_tz":-120,"elapsed":754,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}}},"source":["import os\n","import time\n","import numpy as np\n","import pandas as pd\n","import torch\n","from scipy import stats\n","from torch.utils.data import DataLoader\n","from torch.nn import MSELoss, L1Loss\n","from datasets import TReNDS\n","from datasets.TReNDS import TReNDSDataset\n","from models import resnet, deeplight, resnet_4d\n","from google.colab import output\n","from importlib import reload\n","\n","# reload(TReNDS)\n","reload(resnet)\n","# from datasets.TReNDS import TReNDSDataset\n","from models import resnet\n","\n","if os.name=='posix': google_colab = True\n","else: google_colab = False"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LBZWToNW0UDi","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600121444832,"user_tz":-120,"elapsed":1723,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}},"outputId":"c50278d3-18ee-4a02-8354-7f5973e6b0fc"},"source":["if google_colab:\n","    print('Working from a Google Colab environment')\n","    data_path = '/content/gdrive/My Drive/capita_selecta_cvbm'\n","    root = '/content/gdrive/My Drive/capita_selecta_cvbm'\n","else:\n","    data_path = '/Volumes/External Hard Drive/Documents/University of Twente/Computer Science/Capita Selecta'\n","    root = '../'\n","\n","available_models = ['deeplight',\n","                    'deeplight_tempframe_26',\n","                    'deeplight_resnet10',\n","                    'resnet10',\n","                    'resnet10_4d']\n","\n","model_name = 'resnet10'\n","fold_index = 2\n","\n","# Options\n","opts = {\n","    'rand_seed'  : 1,\n","    'no_cuda'    : False,\n","    'temp_mean'  : False,\n","    'preprocess' : False, #Adds ±1.2s per data sample, per epoch on CPU\n","    'scale_norm' : True,  #Adds no distinctive additional time to processing\n","    'lr'         : 1e-4,\n","    'train_bs'   : 16,\n","    'test_bs'    : 16,\n","    'epochs'     : 50,\n","    'fold_index' : fold_index,\n","    'n_splits'   : 5,\n","    'model_name' : model_name,\n","    'save_at_eps': list(range(1,51)),\n","    'test_at_eps': list(range(1,51)),\n","    'save_dir'   : os.path.join(root, 'results/%s/%s'%(model_name, str(fold_index))),\n","    'resume'     : None, #os.path.join(root, 'results/resnet10/2/epoch_2.pth.tar'),\n","    'pretrain'   : None,\n","}\n","\n","if not os.path.exists(opts['save_dir']):\n","    os.makedirs(opts['save_dir'])\n","    \n","torch.manual_seed(opts['rand_seed'])\n","earlier_epochs = 0"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Working from a Google Colab environment\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5Zy2uvBJ0UDn","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600121459065,"user_tz":-120,"elapsed":11291,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}},"outputId":"566fbdc0-1984-4136-802b-15dc02bf29e8"},"source":["# Generate model\n","assert model_name in available_models\n","if model_name=='deeplight':\n","    model = deeplight.original()\n","elif model_name=='deeplight_tempframe_26':\n","    model = deeplight.original(temp_frame=26)\n","elif model_name=='resnet10':\n","    model = resnet.resnet10(shortcut_type='B', no_cuda=opts['no_cuda'], num_class=1)\n","elif model_name=='resnet10_4d':\n","    model = resnet_4d.resnet10_4d(no_cuda=opts['no_cuda'], num_class=1)\n","    \n","optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=opts['lr'], betas=(.9,.999), eps=1e-08)\n","mse   = MSELoss()\n","mae   = L1Loss()\n","\n","def weighted_mae(preds, lbls):\n","    if opts['no_cuda']:\n","        p = stats.norm.pdf(lbls, 50.034068314837356, 13.538728884495923)\n","        w = torch.FloatTensor(0.02946674564539714/p)\n","    else:\n","        p = stats.norm.pdf(lbls.cpu(), 50.034068314837356, 13.538728884495923)\n","        w = torch.FloatTensor(0.02946674564539714/p).cuda()\n","    return torch.mean(torch.abs(preds - lbls) * w)\n","\n","if not opts['no_cuda']:\n","    model.cuda()\n","    \n","num_params    = sum(p.numel() for p in model.parameters())\n","num_tr_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print('Loaded %s (param: %d, trainable: %d, GPU: %s)'%(model_name, num_params, num_tr_params, not opts['no_cuda']))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Loaded resnet10 (param: 15497537, trainable: 15497537, GPU: True)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tYO27GM00UDq","colab":{}},"source":["# Train from checkpoint\n","if opts['resume']:\n","    if os.path.isfile(opts['resume']):\n","        print('Loading checkpoint from:', opts['resume'])\n","        if opts['no_cuda']:\n","          load_dict = torch.load(opts['resume'], map_location=torch.device('cpu'))\n","        else:\n","          load_dict = torch.load(opts['resume'])\n","        model.load_state_dict(load_dict['state_dict'])\n","        optim.load_state_dict(load_dict['optim'])\n","        earlier_epochs = load_dict['epoch']\n","        print('Earlier epochs:', earlier_epochs)\n","        \n","# Train from pre-trained model\n","elif opts['pretrain']:\n","    if os.path.isfile(opts['pretrain']):\n","        print('Loading pre-trained weights from:', opts['pretrain'])\n","        model_dict = model.state_dict()\n","        pretrain   = torch.load(opts['pretrain'])\n","        pretr_dict = {k:v for k,v in pretrain['state_dict'].items() if k in model_dict.keys() and 'conv1' not in k}\n","        model_dict.update(pretr_dict)\n","        model.load_state_dict(model_dict)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cqnxLn770UDv","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600121464688,"user_tz":-120,"elapsed":1684,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}},"outputId":"3d10299e-41f1-47e4-cc4e-86a99d3295c3"},"source":["# Get dataset\n","train_set    = TReNDSDataset(data_path, 'train', n_splits=opts['n_splits'], fold=fold_index,\n","                             preprocess=opts['preprocess'], norm=opts['scale_norm'],\n","                             temp_mean=opts['temp_mean'])\n","train_loader = DataLoader(train_set, batch_size=opts['train_bs'], shuffle=True, pin_memory=True)\n","test_set     = TReNDSDataset(data_path, 'test', n_splits=opts['n_splits'], fold=fold_index,\n","                             preprocess=opts['preprocess'], norm=opts['scale_norm'],\n","                             temp_mean=opts['temp_mean'])\n","test_loader  = DataLoader(test_set, batch_size=opts['test_bs'], shuffle=False, pin_memory=True)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Loaded dataset with 4702 train samples in fold 2.\n","Loaded dataset with 1175 test samples in fold 2.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Z43MuHbS0UDy","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6bda6d8c-3422-46fc-9723-ed3c6d3cdb88"},"source":["# Train model\n","if not opts['resume']:\n","    log_file = open(os.path.join(opts['save_dir'], 'log.txt'), 'w')\n","    log_file.write('Epoch,set,time,MSE,MAE,Pearson r,p-value\\n')\n","    log_file.flush()\n","    log_file.close()\n","\n","for epoch in range(1+earlier_epochs, opts['epochs']+1+earlier_epochs):\n","    model.train()\n","    start_time = time.time()\n","    batches    = len(train_loader)\n","    batch_id   = 1\n","    tot_mae    = 0.\n","    tot_mse    = 0.\n","    \n","    for batch_data in train_loader:\n","        imgs, lbls   = batch_data\n","\n","        if not opts['no_cuda']:\n","            imgs = imgs.cuda()\n","            lbls = lbls.cuda()\n","        \n","        optim.zero_grad()\n","        preds    = model(imgs)\n","        mae_loss = mae(preds, lbls)\n","        mse_loss = mse(preds, lbls)\n","        loss     = weighted_mae(preds, lbls)\n","        loss.backward() # Optimizing with weighted MAE\n","        if model_name=='deeplight':\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n","        optim.step()\n","        \n","        avg_batch_time = (time.time()-start_time)/batch_id\n","        eta = (batches-batch_id)*avg_batch_time/60\n","        if google_colab:\n","            output.clear('batch_inf')\n","            with output.use_tags('batch_inf'):\n","                print('Training model => Epoch: %d/%d - batch: %d/%d - loss: %.5f (loss) %.5f (MSE) %.5f (MAE) - time: %.1f (avg) %.1f (ETA in min.)'%(epoch,\n","                    opts['epochs']+earlier_epochs, batch_id, batches, loss.item(), mse_loss.item(), mae_loss.item(), avg_batch_time, eta))\n","        else:\n","            print('Training model => Epoch: %d/%d - batch: %d/%d - loss: %.5f (loss) %.5f (MSE) %.5f (MAE) - time: %.1f (avg) %.1f (ETA in min.)'%(epoch,\n","                opts['epochs']+earlier_epochs, batch_id, batches, loss.item(), mse_loss.item(), mae_loss.item(), avg_batch_time, eta), end='\\r')\n","        \n","        tot_mae+=mae_loss.item()\n","        tot_mse+=mse_loss.item()\n","        batch_id+=1\n","    \n","    avg_mae  = tot_mae/batches\n","    avg_mse  = tot_mse/batches\n","    tot_time = time.time()-start_time\n","    \n","    log_file = open(os.path.join(opts['save_dir'], 'log.txt'), 'a')\n","    log_file.write('%d,train,%.1f,%.5f,%.5f\\n'%(epoch, tot_time, avg_mse, avg_mae))\n","    log_file.flush()\n","    log_file.close()\n","            \n","    if epoch==opts['epochs'] or epoch in opts['save_at_eps']:\n","        filename = os.path.join(opts['save_dir'], 'epoch_%d.pth.tar'%(epoch))\n","        torch.save({'epoch':epoch, 'state_dict':model.state_dict(),\n","            'optim':optim.state_dict()}, filename)\n","        \n","    if epoch in opts['test_at_eps']:\n","        results = evaluate_model(test_loader, model, mae, mse, epoch, opts)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training model => Epoch: 9/50 - batch: 51/294 - loss: 7.13686 (loss) 22.47421 (MSE) 4.20535 (MAE) - time: 10.1 (avg) 40.8 (ETA in min.)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mVLQf8hDOWiM","colab":{},"executionInfo":{"status":"ok","timestamp":1600121468471,"user_tz":-120,"elapsed":802,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}}},"source":["def evaluate_model(test_loader, model, mae, mse, epoch, opts):\n","    model.eval()\n","    start_time = time.time()\n","    batches    = len(test_loader)\n","    all_preds  = []\n","    all_labls  = []\n","    tot_mae    = 0.\n","    tot_mse    = 0.\n","\n","    with torch.no_grad():\n","        batch_id = 1\n","        for batch_data in test_loader:\n","            imgs, lbls  = batch_data\n","\n","            if not opts['no_cuda']:\n","                imgs = imgs.cuda()\n","                lbls = lbls.cuda()\n","            \n","            preds    = model(imgs)\n","            mae_loss = mae(preds, lbls)\n","            mse_loss = mse(preds, lbls)\n","            loss     = weighted_mae(preds, lbls)\n","\n","            avg_batch_time = (time.time()-start_time)/batch_id\n","            eta = (batches-batch_id)*avg_batch_time/60\n","            if google_colab:\n","                output.clear('batch_inf')\n","                with output.use_tags('batch_inf'):\n","                    print('Evaluating model => Batch: %d/%d - loss: %.5f (loss) %.5f (MSE) %.5f (MAE) - time: %.1f (avg) %.1f (ETA in min.)'%(batch_id,\n","                        batches, loss.item(), mse_loss.item(), mae_loss.item(), avg_batch_time, eta))\n","            \n","            tot_mae+=mae_loss.item()\n","            tot_mse+=mse_loss.item()\n","            all_preds.append(preds.data.cpu().numpy().flatten())\n","            all_labls.append(lbls.data.cpu().numpy().flatten())\n","            batch_id+=1\n","\n","    avg_mae  = tot_mae/batches\n","    avg_mse  = tot_mse/batches\n","    tot_time = time.time()-start_time\n","    \n","    all_preds = np.concatenate(all_preds, axis=0)\n","    all_labls = np.concatenate(all_labls, axis=0)\n","    filename  = os.path.join(opts['save_dir'], 'preds_epoch_%d.csv'%(epoch))\n","    results   = pd.DataFrame(data={'Pred':all_preds, 'Label':all_labls})\n","    results.to_csv(filename, index=False)\n","\n","    r, p = stats.pearsonr(all_preds.tolist(), all_labls.tolist())\n","\n","    log_file = open(os.path.join(opts['save_dir'], 'log.txt'), 'a')\n","    log_file.write('%d,test,%.1f,%.5f,%.5f,%.5f,%.7f\\n'%(epoch, tot_time, avg_mse, avg_mae, r, p))\n","    log_file.flush()\n","    log_file.close()\n","\n","    output.clear('batch_inf')\n","    print('Average loss: %.3f (MSE) %.3f (MAE)'%(avg_mae,avg_mse))\n","\n","    return results"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Edc943R6p1dL","colab_type":"text"},"source":["**Perform an isolated evaluation and print 20 predictions**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LMNYHeCvklXA","colab":{"base_uri":"https://localhost:8080/","height":686},"executionInfo":{"status":"ok","timestamp":1598698367127,"user_tz":-120,"elapsed":10270507,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}},"outputId":"e18d8edc-8b22-4501-e19a-2fc544645fd1"},"source":["results = evaluate_model(test_loader, model, mae, mse, 3, opts)\n","results.head(20)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Average loss: 13.095 (MSE) 266.570 (MAE)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pred</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>58.695084</td>\n","      <td>64.203110</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>58.431183</td>\n","      <td>33.404690</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>58.427494</td>\n","      <td>66.532631</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>58.449802</td>\n","      <td>71.413017</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>58.801823</td>\n","      <td>57.436077</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>58.471733</td>\n","      <td>53.583805</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>58.556309</td>\n","      <td>59.580853</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>58.558262</td>\n","      <td>28.442741</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>58.730824</td>\n","      <td>42.941154</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>58.607960</td>\n","      <td>61.811382</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>58.524063</td>\n","      <td>44.423908</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>58.569656</td>\n","      <td>76.538643</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>58.569653</td>\n","      <td>55.456978</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>58.121727</td>\n","      <td>36.961174</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>58.335857</td>\n","      <td>33.404690</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>58.739197</td>\n","      <td>53.583805</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>58.345596</td>\n","      <td>36.961174</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>58.565403</td>\n","      <td>36.961174</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>58.697468</td>\n","      <td>59.580853</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>58.817436</td>\n","      <td>59.580853</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Pred      Label\n","0   58.695084  64.203110\n","1   58.431183  33.404690\n","2   58.427494  66.532631\n","3   58.449802  71.413017\n","4   58.801823  57.436077\n","5   58.471733  53.583805\n","6   58.556309  59.580853\n","7   58.558262  28.442741\n","8   58.730824  42.941154\n","9   58.607960  61.811382\n","10  58.524063  44.423908\n","11  58.569656  76.538643\n","12  58.569653  55.456978\n","13  58.121727  36.961174\n","14  58.335857  33.404690\n","15  58.739197  53.583805\n","16  58.345596  36.961174\n","17  58.565403  36.961174\n","18  58.697468  59.580853\n","19  58.817436  59.580853"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"5LIA72Pzpf79","colab_type":"text"},"source":["**Calculate losses from predictions csv file**"]},{"cell_type":"code","metadata":{"id":"gy__JhKpENcz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598384008821,"user_tz":-120,"elapsed":480,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}},"outputId":"59866f45-1788-4392-ff17-5a7f66884416"},"source":["results = pd.read_csv('../results/resnet10_4d/0/preds_epoch_2.csv')\n","\n","all_preds = results['Pred'].to_list()\n","all_labls = results['Label'].to_list()\n","\n","mae = 0.\n","mse = 0.\n","for i in range(len(all_preds)):\n","    pred = all_preds[i]\n","    labl = all_labls[i]\n","    mae += np.abs(pred-labl)\n","    mse += (pred-labl)**2\n","\n","mae /= len(all_preds)\n","mse /= len(all_preds)\n","print(mae, mse)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["10.847196312925162 181.8990364785956\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PVcGNAHQpmqP","colab_type":"text"},"source":["**Calculate mean, minimum and maximum values of dataset set**"]},{"cell_type":"code","metadata":{"id":"HD07UmWkpSdW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598465576827,"user_tz":-120,"elapsed":3281233,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}},"outputId":"6672f029-1342-41c7-ba23-25a5f17ce82a"},"source":["mean = 0.0\n","min  = 999.0\n","max  = -999.0\n","\n","batch_id = 1\n","batches  = len(train_loader)\n","for batch_data in train_loader:\n","    assert opts['train_bs']==1\n","    img, lbls = batch_data\n","\n","    img_mean = torch.mean(img).item()\n","    img_min  = torch.min(img).item()\n","    img_max  = torch.max(img).item()\n","\n","    mean+=img_mean\n","\n","    if img_min<min:\n","        min = img_min\n","    if img_max>max:\n","        max = img_max\n","\n","    output.clear('batch_inf')\n","    with output.use_tags('batch_inf'):\n","        print('Calculating => Batch: %d/%d'%(batch_id, batches))\n","    batch_id+=1\n","\n","mean/=batches\n","\n","output.clear('batch_inf')\n","with output.use_tags('batch_inf'):\n","    print('Mean:', mean, 'Min:', min, 'Max:', max, 'Fold:', fold_index)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mean: 0.0513693805085198 Min: -26.703125 Max: 25.53125 Fold: 4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QcIxNEDk-Vqa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1598469414589,"user_tz":-120,"elapsed":3671401,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}},"outputId":"32fe4692-70a4-4833-f2e0-caff0bf184ac"},"source":["mean = 0.0\n","\n","batch_id = 1\n","batches  = len(train_loader)\n","for batch_data in train_loader:\n","    img, lbls = batch_data\n","    img_mean = torch.mean(img).item()\n","    mean+=img_mean\n","\n","    output.clear('batch_inf')\n","    with output.use_tags('batch_inf'):\n","        print('Calculating => Batch: %d/%d'%(batch_id, batches))\n","    batch_id+=1\n","\n","batch_id = 1\n","batches  = len(test_loader)\n","for batch_data in test_loader:\n","    img, lbls = batch_data\n","    img_mean = torch.mean(img).item()\n","    mean+=img_mean\n","    \n","    output.clear('batch_inf')\n","    with output.use_tags('batch_inf'):\n","        print('Calculating => Batch: %d/%d'%(batch_id, batches))\n","    batch_id+=1\n","\n","mean/=(len(train_loader)+len(test_loader))\n","print('Mean:', mean)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Calculating => Batch: 1175/1175\n"],"name":"stdout"},{"output_type":"stream","text":["Mean: 0.051363078512534084\n"],"name":"stdout"}]}]}