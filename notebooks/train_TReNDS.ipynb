{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_TReNDS.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"ND0y3lqv0UDX","colab":{}},"source":["## Lines for Google Colab to import Drive repository and configure GitHub\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd /content/gdrive/My Drive/capita_selecta_cvbm/notebooks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jMuWtcXTZrwG","colab":{}},"source":["## Lines for Google Colab to push and pull form GitHub repository\n","# %cd /content/gdrive/My Drive/capita_selecta_cvbm\n","# !git pull origin master\n","\n","# !git remote rm origin\n","# !git remote add origin https://Beerend:XXXXX@github.com/Beerend/TReNDS.git\n","\n","# !git pull origin master\n","# !git status\n","# !git add train_TReNDS.ipynb\n","# !git commit -m 'Added MAE loss'\n","# !git push origin master"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oNvdaMeg0UDe","colab":{},"executionInfo":{"status":"ok","timestamp":1598000755053,"user_tz":-120,"elapsed":552,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}}},"source":["import os\n","import time\n","import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import DataLoader\n","from torch.nn import MSELoss, L1Loss\n","from datasets import TReNDS\n","from datasets.TReNDS import TReNDSDataset\n","from models import resnet, deeplight\n","from google.colab import output\n","from importlib import reload\n","\n","# reload(TReNDS)\n","# reload(deeplight)\n","# from datasets.TReNDS import TReNDSDataset\n","# from models import deeplight\n","\n","#ResNet3D is from SeuTao (https://github.com/SeuTao/RSNA2019_Intracranial-Hemorrhage-Detection/tree/bbdb1e1d645953ef4b2f23c87b6fba44aff023ea/3DNet)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LBZWToNW0UDi","colab":{},"executionInfo":{"status":"ok","timestamp":1598000769195,"user_tz":-120,"elapsed":535,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}}},"source":["# Home PC\n","# data_path = '/Volumes/External Hard Drive/Documents/University of Twente/Computer Science/Capita Selecta'\n","# root = '../'\n","\n","# Google Colab\n","data_path = '/content/gdrive/My Drive/capita_selecta_cvbm'\n","root = '/content/gdrive/My Drive/capita_selecta_cvbm'\n","\n","model_name = 'deeplight_tempframe_26'\n","fold_index = 0\n","\n","# Options\n","opts = {\n","    'rand_seed'  : 1,\n","    'no_cuda'    : True,\n","    'lr'         : 1e-4,\n","    'train_bs'   : 32,\n","    'test_bs'    : 32,\n","    'epochs'     : 60,\n","    'fold_index' : fold_index,\n","    'n_splits'   : 5,\n","    'model_name' : model_name,\n","    'save_at_eps': list(range(1,61)),\n","    'test_at_eps': list(range(1,61)),\n","    'save_dir'   : os.path.join(root, 'results/%s/%s'%(model_name, str(fold_index))),\n","    'resume'     : None, #os.path.join(root, 'results/deeplight/0/epoch_5.pth.tar'),\n","    'pretrain'   : None,\n","}\n","\n","if not os.path.exists(opts['save_dir']):\n","    os.makedirs(opts['save_dir'])\n","    \n","torch.manual_seed(opts['rand_seed'])\n","earlier_epochs = 0"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5Zy2uvBJ0UDn","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598000876474,"user_tz":-120,"elapsed":600,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}},"outputId":"87ea2ce9-15c7-47bd-9a78-b4a4c1902d02"},"source":["# Generate model\n","assert model_name in ['deeplight', 'deeplight_tempframe_26', 'deeplight_resnet10', 'resnet10']\n","if model_name=='deeplight': model = deeplight.original()\n","elif model_name=='deeplight_tempframe_26': model = deeplight.original(temp_frame=26)\n","elif model_name=='resnet10': model = resnet.resnet10(shortcut_type='B', no_cuda=opts['no_cuda'], num_class=1)\n","\n","optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=opts['lr']) #, betas=(.9,.999), eps=1e-08)\n","mse   = MSELoss()\n","mae   = L1Loss()\n","\n","if not opts['no_cuda']:\n","    model.cuda()\n","    \n","num_params    = sum(p.numel() for p in model.parameters())\n","num_tr_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print('Loaded %s (param: %d, trainable: %d, GPU: %s)'%(model_name, num_params, num_tr_params, not opts['no_cuda']))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Loaded deeplight_tempframe_26 (param: 220945, trainable: 220945, GPU: False)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tYO27GM00UDq","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597997706532,"user_tz":-120,"elapsed":536,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}},"outputId":"f41c30a0-816e-43fc-e016-e140055452e6"},"source":["# Train from checkpoint\n","if opts['resume']:\n","    if os.path.isfile(opts['resume']):\n","        print('Loading checkpoint from:', opts['resume'])\n","        load_dict = torch.load(opts['resume']) #, map_location=torch.device('cpu'))\n","        model.load_state_dict(load_dict['state_dict'])\n","        optim.load_state_dict(load_dict['optim'])\n","        earlier_epochs = load_dict['epoch']\n","        \n","# Train from pre-trained model\n","elif opts['pretrain']:\n","    if os.path.isfile(opts['pretrain']):\n","        print('Loading pre-trained weights from:', opts['pretrain'])\n","        model_dict = model.state_dict()\n","        pretrain   = torch.load(opts['pretrain'])\n","        pretr_dict = {k:v for k,v in pretrain['state_dict'].items() if k in model_dict.keys() and 'conv1' not in k}\n","        model_dict.update(pretr_dict)\n","        model.load_state_dict(model_dict)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Loading checkpoint from: /content/gdrive/My Drive/capita_selecta_cvbm/results/deeplight/0/epoch_5.pth.tar\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cqnxLn770UDv","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1598000884577,"user_tz":-120,"elapsed":692,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}},"outputId":"cf6f797f-e4a8-4a75-8eb6-884ed75962bc"},"source":["# Get dataset\n","train_set    = TReNDSDataset(data_path, 'train', n_splits=opts['n_splits'], fold=fold_index, norm=True)\n","train_loader = DataLoader(train_set, batch_size=opts['train_bs'], shuffle=True, pin_memory=True)\n","test_set     = TReNDSDataset(data_path, 'test', n_splits=opts['n_splits'], fold=fold_index, norm=True)\n","test_loader  = DataLoader(test_set, batch_size=opts['test_bs'], shuffle=False, pin_memory=True)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Loaded dataset with 4701 train samples in fold 0.\n","Loaded dataset with 1176 test samples in fold 0.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Z43MuHbS0UDy","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"76a53322-17af-476a-f7af-09e904754f9e"},"source":["# Train model\n","\n","for epoch in range(1+earlier_epochs, opts['epochs']+1+earlier_epochs):\n","    # TODO: adjust learning rate\n","\n","    model.train()\n","    start_time = time.time()\n","    batches    = len(train_loader)\n","\n","    if opts['resume']:\n","        log_file   = open(os.path.join(opts['save_dir'], 'log.txt'), 'a')\n","    else:\n","        log_file   = open(os.path.join(opts['save_dir'], 'log.txt'), 'w')\n","        log_file.write('Epoch,set,MSE,MAE,time\\n')\n","        log_file.flush()\n","\n","    batch_id = 1\n","    tot_mae  = 0.\n","    tot_mse  = 0.\n","    for batch_data in train_loader:\n","        imgs, lbls   = batch_data\n","        batch_id_tot = batch_id+(epoch-earlier_epochs-1)*batches\n","\n","        if not opts['no_cuda']:\n","            imgs = imgs.cuda()\n","            lbls = lbls.cuda()\n","        \n","        optim.zero_grad()\n","        preds    = model(imgs)\n","        mae_loss = mae(preds, lbls)\n","        mse_loss = mse(preds, lbls)\n","        mse_loss.backward()\n","        if model_name=='deeplight':\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n","        optim.step()\n","        \n","        avg_batch_time = (time.time()-start_time)/batch_id_tot\n","        output.clear('batch_inf')\n","        with output.use_tags('batch_inf'):\n","            print('Training model => Epoch: %d/%d - batch: %d/%d - loss: %.5f (MSE) %.5f (MAE) - time: %.3f'%(epoch,\n","                opts['epochs']+earlier_epochs, batch_id, batches, mse_loss.item(), mae_loss.item(), avg_batch_time))\n","        \n","#         print('Training model => Epoch: %d/%d - batch: %d/%d - loss: %.5f (MSE) %.5f (MAE) - time: %.3f'%(epoch,\n","#             opts['epochs']+earlier_epochs, batch_id, batches, mse_loss.item(), mae_loss.item(), avg_batch_time), end='\\r')\n","        \n","        tot_mae+=mae_loss.item()\n","        tot_mse+=mse_loss.item()\n","        batch_id+=1\n","    \n","    avg_mae  = tot_mae/batches\n","    avg_mse  = tot_mse/batches\n","    tot_time = time.time()-start_time\n","    log_file.write('%d,train,%.5f,%.5f,%.1f\\n'%(epoch, avg_mse, avg_mae, tot_time))\n","    log_file.flush()\n","    log_file.close()\n","            \n","    if epoch==opts['epochs'] or epoch in opts['save_at_eps']:\n","        filename = os.path.join(opts['save_dir'], 'epoch_%d.pth.tar'%(epoch))\n","        torch.save({'epoch':epoch, 'state_dict':model.state_dict(),\n","            'optim':optim.state_dict()}, filename)\n","        \n","    if epoch in opts['test_at_eps']:\n","        results = evaluate_model(test_loader, model, mae, mse, epoch, opts)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Evaluating model => Batch: 2/37 - loss: 121.75878 (MSE) 8.61017 (MAE)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mVLQf8hDOWiM","colab":{},"executionInfo":{"status":"ok","timestamp":1598000889258,"user_tz":-120,"elapsed":572,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}}},"source":["def evaluate_model(test_loader, model, mae, mse, epoch, opts):\n","    model.eval()\n","    start_time = time.time()\n","    batches    = len(test_loader)\n","    all_preds  = []\n","    all_labls  = []\n","    tot_mae    = 0.\n","    tot_mse    = 0.\n","    log_file   = open(os.path.join(opts['save_dir'], 'log.txt'), 'a')\n","\n","    with torch.no_grad():\n","        batch_id = 1\n","        for batch_data in test_loader:\n","            imgs, lbls  = batch_data\n","\n","            if not opts['no_cuda']:\n","                imgs = imgs.cuda()\n","                lbls = lbls.cuda()\n","            \n","            preds    = model(imgs)\n","            mae_loss = mae(preds, lbls)\n","            mse_loss = mse(preds, lbls)\n","\n","            output.clear('batch_inf')\n","            with output.use_tags('batch_inf'):\n","                print('Evaluating model => Batch: %d/%d - loss: %.5f (MSE) %.5f (MAE)'%(batch_id,\n","                    batches, mse_loss.item(), mae_loss.item()))\n","            \n","            tot_mae+=mae_loss.item()\n","            tot_mse+=mse_loss.item()\n","            all_preds.append(preds.data.cpu().numpy().flatten())\n","            all_labls.append(lbls.data.cpu().numpy().flatten())\n","            batch_id+=1\n","\n","    avg_mae  = tot_mae/batches\n","    avg_mse  = tot_mse/batches\n","    tot_time = time.time()-start_time\n","\n","    log_file.write('%d,test,%.5f,%.5f,%.1f\\n'%(epoch, avg_mse, avg_mae, tot_time))\n","    log_file.flush()\n","    log_file.close()\n","\n","    all_preds = np.concatenate(all_preds, axis=0)\n","    all_labls = np.concatenate(all_labls, axis=0)\n","    filename  = os.path.join(opts['save_dir'], 'preds_epoch_%d.csv'%(epoch))\n","    results   = pd.DataFrame(data={'Pred':all_preds, 'Label':all_labls})\n","    results.to_csv(filename, index=False)\n","\n","    output.clear('batch_inf')\n","    print('Average loss: %.3f (MSE) %.3f (MAE)'%(avg_mae,avg_mse))\n","\n","    return results"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"LMNYHeCvklXA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":436},"executionInfo":{"status":"ok","timestamp":1597999728331,"user_tz":-120,"elapsed":1984409,"user":{"displayName":"Beerend Gerats","photoUrl":"","userId":"02409374618171011835"}},"outputId":"3e887b9f-fb68-4dd3-eb60-09ddcf965046"},"source":["evaluate_model(test_loader, model, mae, mse, 5, opts)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Average loss: 11.102 (MSE) 188.586 (MAE)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pred</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>52.161644</td>\n","      <td>38.617382</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>52.289677</td>\n","      <td>35.326580</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>52.289486</td>\n","      <td>35.326580</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>52.289654</td>\n","      <td>64.203110</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>52.289528</td>\n","      <td>66.532631</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1171</th>\n","      <td>52.289722</td>\n","      <td>57.436077</td>\n","    </tr>\n","    <tr>\n","      <th>1172</th>\n","      <td>52.289742</td>\n","      <td>48.948757</td>\n","    </tr>\n","    <tr>\n","      <th>1173</th>\n","      <td>52.289402</td>\n","      <td>42.941154</td>\n","    </tr>\n","    <tr>\n","      <th>1174</th>\n","      <td>52.289536</td>\n","      <td>14.257265</td>\n","    </tr>\n","    <tr>\n","      <th>1175</th>\n","      <td>52.116913</td>\n","      <td>55.456978</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1176 rows × 2 columns</p>\n","</div>"],"text/plain":["           Pred      Label\n","0     52.161644  38.617382\n","1     52.289677  35.326580\n","2     52.289486  35.326580\n","3     52.289654  64.203110\n","4     52.289528  66.532631\n","...         ...        ...\n","1171  52.289722  57.436077\n","1172  52.289742  48.948757\n","1173  52.289402  42.941154\n","1174  52.289536  14.257265\n","1175  52.116913  55.456978\n","\n","[1176 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":10}]}]}