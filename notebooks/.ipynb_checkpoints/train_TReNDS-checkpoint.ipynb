{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30062,
     "status": "ok",
     "timestamp": 1597914795930,
     "user": {
      "displayName": "Beerend Gerats",
      "photoUrl": "",
      "userId": "02409374618171011835"
     },
     "user_tz": -120
    },
    "id": "ND0y3lqv0UDX",
    "outputId": "76c0bb9c-4506-42c3-fdbf-4314c813adb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n",
      "/content/gdrive/My Drive/capita_selecta_cvbm/notebooks\n"
     ]
    }
   ],
   "source": [
    "## Lines for Google Colab to import Drive repository and configure GitHub\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "%cd /content/gdrive/My Drive/capita_selecta_cvbm/notebooks\n",
    "\n",
    "!git config --global user.email \"XXXXX\"\n",
    "!git config --global user.name \"Beerend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29509,
     "status": "ok",
     "timestamp": 1597914842600,
     "user": {
      "displayName": "Beerend Gerats",
      "photoUrl": "",
      "userId": "02409374618171011835"
     },
     "user_tz": -120
    },
    "id": "jMuWtcXTZrwG",
    "outputId": "7eecf51b-efd5-4831-e609-fcb926b0f271"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
      "\n",
      "\t\u001b[31mmodified:   datasets/__pycache__/TReNDS.cpython-36.pyc\u001b[m\n",
      "\t\u001b[31mmodified:   train_TReNDS.ipynb\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\n",
      "\t\u001b[31m../results/\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "## Lines for Google Colab to push and pull form GitHub repository\n",
    "# %cd /content/gdrive/My Drive/capita_selecta_cvbm\n",
    "# !git pull origin master\n",
    "\n",
    "# !git remote rm origin\n",
    "# !git remote add origin https://Beerend:XXXXX@github.com/Beerend/TReNDS.git\n",
    "\n",
    "# !git pull origin master\n",
    "!git status\n",
    "# !git add train_TReNDS.ipynb\n",
    "# !git commit -m 'Added MAE loss'\n",
    "# !git push origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oNvdaMeg0UDe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import MSELoss, L1Loss\n",
    "from datasets import TReNDS\n",
    "from datasets.TReNDS import TReNDSDataset\n",
    "from models import resnet, deeplight\n",
    "# from google.colab import output\n",
    "from importlib import reload\n",
    "\n",
    "reload(TReNDS)\n",
    "reload(deeplight)\n",
    "from datasets.TReNDS import TReNDSDataset\n",
    "from models import deeplight\n",
    "\n",
    "#ResNet3D is from SeuTao (https://github.com/SeuTao/RSNA2019_Intracranial-Hemorrhage-Detection/tree/bbdb1e1d645953ef4b2f23c87b6fba44aff023ea/3DNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LBZWToNW0UDi"
   },
   "outputs": [],
   "source": [
    "# Home PC\n",
    "data_path = '/Volumes/External Hard Drive/Documents/University of Twente/Computer Science/Capita Selecta'\n",
    "root = '../'\n",
    "\n",
    "# Google Colab\n",
    "# data_path = '/content/gdrive/My Drive/capita_selecta_cvbm'\n",
    "# root = '/content/gdrive/My Drive/capita_selecta_cvbm'\n",
    "\n",
    "model_name = 'deeplight'\n",
    "fold_index = 0\n",
    "\n",
    "# Options\n",
    "opts = {\n",
    "    'rand_seed'  : 1,\n",
    "    'no_cuda'    : True,\n",
    "    'lr'         : 3e-4,\n",
    "    'train_bs'   : 1,\n",
    "    'test_bs'    : 1,\n",
    "    'epochs'     : 1,\n",
    "    'fold_index' : fold_index,\n",
    "    'n_splits'   : 5,\n",
    "    'model_name' : model_name,\n",
    "    'save_at_eps': [], #[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\n",
    "    'test_at_eps': [], #[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\n",
    "    'save_dir'   : os.path.join(root, 'results/%s/%s'%(model_name, str(fold_index))),\n",
    "    'resume'     : None, #os.path.join(root, 'results/resnet10/0/epoch_4.pth.tar'),\n",
    "    'pretrain'   : None,\n",
    "}\n",
    "\n",
    "if not os.path.exists(opts['save_dir']):\n",
    "    os.makedirs(opts['save_dir'])\n",
    "    \n",
    "torch.manual_seed(opts['rand_seed'])\n",
    "earlier_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Zy2uvBJ0UDn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded deeplight (param: 220945, trainable: 220945, GPU: False)\n"
     ]
    }
   ],
   "source": [
    "# Generate model\n",
    "assert model_name in ['deeplight', 'deeplight_resnet10', 'resnet10']\n",
    "if model_name=='deeplight': model = deeplight.original()\n",
    "elif model_name=='resnet10': model = resnet.resnet10(shortcut_type='B', no_cuda=opts['no_cuda'], num_class=1)\n",
    "\n",
    "optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=opts['lr'], betas=(.9,.999), eps=1e-08)\n",
    "mse   = MSELoss()\n",
    "mae   = L1Loss()\n",
    "\n",
    "if not opts['no_cuda']:\n",
    "    model.cuda()\n",
    "    \n",
    "num_params    = sum(p.numel() for p in model.parameters())\n",
    "num_tr_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('Loaded %s (param: %d, trainable: %d, GPU: %s)'%(model_name, num_params, num_tr_params, not opts['no_cuda']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3927,
     "status": "ok",
     "timestamp": 1597830320154,
     "user": {
      "displayName": "Beerend Gerats",
      "photoUrl": "",
      "userId": "02409374618171011835"
     },
     "user_tz": -120
    },
    "id": "tYO27GM00UDq",
    "outputId": "2ffa8401-5e6f-4318-fe38-65c795c2b7b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from: /content/gdrive/My Drive/capita_selecta_cvbm/results/resnet10/0/epoch_4.pth.tar\n"
     ]
    }
   ],
   "source": [
    "# Train from checkpoint\n",
    "if opts['resume']:\n",
    "    if os.path.isfile(opts['resume']):\n",
    "        print('Loading checkpoint from:', opts['resume'])\n",
    "        load_dict = torch.load(opts['resume'])\n",
    "        model.load_state_dict(load_dict['state_dict'])\n",
    "        optim.load_state_dict(load_dict['optim'])\n",
    "        earlier_epochs = load_dict['epoch']\n",
    "        \n",
    "# Train from pre-trained model\n",
    "elif opts['pretrain']:\n",
    "    if os.path.isfile(opts['pretrain']):\n",
    "        print('Loading pre-trained weights from:', opts['pretrain'])\n",
    "        model_dict = model.state_dict()\n",
    "        pretrain   = torch.load(opts['pretrain'])\n",
    "        pretr_dict = {k:v for k,v in pretrain['state_dict'].items() if k in model_dict.keys() and 'conv1' not in k}\n",
    "        model_dict.update(pretr_dict)\n",
    "        model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2029,
     "status": "ok",
     "timestamp": 1597830322192,
     "user": {
      "displayName": "Beerend Gerats",
      "photoUrl": "",
      "userId": "02409374618171011835"
     },
     "user_tz": -120
    },
    "id": "cqnxLn770UDv",
    "outputId": "145a5651-eb7f-4205-b364-a6747c512c61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 4701 train samples in fold 0.\n",
      "Loaded dataset with 1176 test samples in fold 0.\n"
     ]
    }
   ],
   "source": [
    "# Get dataset\n",
    "train_set    = TReNDSDataset(data_path, 'train', n_splits=opts['n_splits'], fold=fold_index)\n",
    "train_loader = DataLoader(train_set, batch_size=opts['train_bs'], shuffle=True, pin_memory=True)\n",
    "test_set     = TReNDSDataset(data_path, 'test', n_splits=opts['n_splits'], fold=fold_index)\n",
    "test_loader  = DataLoader(test_set, batch_size=opts['test_bs'], shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2975119,
     "status": "error",
     "timestamp": 1597833302448,
     "user": {
      "displayName": "Beerend Gerats",
      "photoUrl": "",
      "userId": "02409374618171011835"
     },
     "user_tz": -120
    },
    "id": "Z43MuHbS0UDy",
    "outputId": "31ff8dd2-d777-47ba-ccb2-3c37fae06c5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model => Epoch: 1/1 - batch: 28/4701 - loss: 238.85687 (MSE) 15.45500 (MAE) - time: 19.8893\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-91927bed28fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpreds\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mmae_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mmse_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/University of Twente/Computer Science/Capita Selecta/capita_selecta_cvbm/notebooks/models/deeplight.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch_data)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    415\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 416\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model.train()\n",
    "start_time = time.time()\n",
    "batches    = len(train_loader)\n",
    "if opts['resume']:\n",
    "  log_file   = open(os.path.join(opts['save_dir'], 'log.txt'), 'a')\n",
    "else:\n",
    "  log_file   = open(os.path.join(opts['save_dir'], 'log.txt'), 'w')\n",
    "  log_file.write('Epoch,set,MSE,MAE,time\\n')\n",
    "  log_file.flush()\n",
    "\n",
    "for epoch in range(1+earlier_epochs, opts['epochs']+1+earlier_epochs):\n",
    "    # TODO: adjust learning rate\n",
    "\n",
    "    batch_id = 1\n",
    "    tot_mae  = 0.\n",
    "    tot_mse  = 0.\n",
    "    for batch_data in train_loader:\n",
    "        imgs, lbls   = batch_data\n",
    "        batch_id_tot = batch_id+(epoch-earlier_epochs-1)*batches\n",
    "\n",
    "        if not opts['no_cuda']:\n",
    "            imgs = imgs.cuda()\n",
    "            lbls = lbls.cuda()\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        preds    = model(imgs)\n",
    "        mae_loss = mae(preds, lbls)\n",
    "        mse_loss = mse(preds, lbls)\n",
    "        mse_loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        avg_batch_time = (time.time()-start_time)/batch_id_tot\n",
    "#         output.clear('batch_inf')\n",
    "#         with output.use_tags('batch_inf'):\n",
    "#             print('Training model => Epoch: %d/%d - batch: %d/%d - loss: %.5f (MSE) %.5f (MAE) - time: %.3f'%(epoch,\n",
    "#                 opts['epochs']+earlier_epochs, batch_id, batches, mse_loss.item(), mae_loss.item(), avg_batch_time))\n",
    "        \n",
    "        print('Training model => Epoch: %d/%d - batch: %d/%d - loss: %.5f (MSE) %.5f (MAE) - time: %.3f'%(epoch,\n",
    "            opts['epochs']+earlier_epochs, batch_id, batches, mse_loss.item(), mae_loss.item(), avg_batch_time), end='\\r')\n",
    "        \n",
    "        tot_mae+=mae_loss.item()\n",
    "        tot_mse+=mse_loss.item()\n",
    "        batch_id+=1\n",
    "    \n",
    "    avg_mae  = tot_mae/batches\n",
    "    avg_mse  = tot_mse/batches\n",
    "    tot_time = time.time()-start_time\n",
    "    log_file.write('%d,train,%.5f,%.5f,%.1f\\n'%(epoch, avg_mse, avg_mae, tot_time))\n",
    "    log_file.flush()\n",
    "            \n",
    "    if epoch==opts['epochs'] or epoch in opts['save_at_eps']:\n",
    "        filename = os.path.join(opts['save_dir'], 'epoch_%d.pth.tar'%(epoch))\n",
    "        torch.save({'epoch':epoch, 'state_dict':model.state_dict(),\n",
    "            'optim':optim.state_dict()}, filename)\n",
    "        \n",
    "    if epoch in opts['test_at_eps']:\n",
    "        results = evaluate_model(test_loader, model, mae, mse, epoch, opts)\n",
    "\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mVLQf8hDOWiM"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(test_loader, model, mae, mse, epoch, opts):\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    batches    = len(test_loader)\n",
    "    all_preds  = []\n",
    "    all_labls  = []\n",
    "    tot_mae    = 0.\n",
    "    tot_mse    = 0.\n",
    "    log_file   = open(os.path.join(opts['save_dir'], 'log.txt'), 'a')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_id = 1\n",
    "        for batch_data in test_loader:\n",
    "            imgs, lbls  = batch_data\n",
    "\n",
    "            if not opts['no_cuda']:\n",
    "                imgs = imgs.cuda()\n",
    "                lbls = lbls.cuda()\n",
    "            \n",
    "            preds    = model(imgs)\n",
    "            mae_loss = mae(preds, lbls)\n",
    "            mse_loss = mse(preds, lbls)\n",
    "\n",
    "            output.clear('batch_inf')\n",
    "            with output.use_tags('batch_inf'):\n",
    "                print('Evaluating model => Batch: %d/%d - loss: %.5f (MSE) %.5f (MSE)'%(batch_id,\n",
    "                    batches, mse_loss.item(), mae_loss.item()))\n",
    "            \n",
    "            tot_mae+=mae_loss.item()\n",
    "            tot_mse+=mse_loss.item()\n",
    "            all_preds.append(preds.data.cpu().numpy().flatten())\n",
    "            all_labls.append(lbls.data.cpu().numpy().flatten())\n",
    "            batch_id+=1\n",
    "\n",
    "    avg_mae  = tot_mae/batches\n",
    "    avg_mse  = tot_mse/batches\n",
    "    tot_time = time.time()-start_time\n",
    "\n",
    "    log_file.write('%d,test,%.5f,%.5f,%.1f\\n'%(epoch, avg_mse, avg_mae, tot_time))\n",
    "    log_file.flush()\n",
    "    log_file.close()\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    all_labls = np.concatenate(all_labls, axis=0)\n",
    "    filename  = os.path.join(opts['save_dir'], 'preds_epoch_%d.csv'%(epoch))\n",
    "    results   = pd.DataFrame(data={'Pred':all_preds, 'Label':all_labls})\n",
    "    results.to_csv(filename, index=False)\n",
    "\n",
    "    output.clear('batch_inf')\n",
    "    print('Average loss: %.3f (MSE) %.3f (MAE)'%(avg_mae,avg_mse))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 483,
     "status": "ok",
     "timestamp": 1597763959100,
     "user": {
      "displayName": "Beerend Gerats",
      "photoUrl": "",
      "userId": "02409374618171011835"
     },
     "user_tz": -120
    },
    "id": "RKOpD0pBH-wU",
    "outputId": "f3d20ab9-e053-4ac1-8152-d7c2dfef2b55"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.543968</td>\n",
       "      <td>38.617382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.978638</td>\n",
       "      <td>35.326580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.009800</td>\n",
       "      <td>35.326580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.501141</td>\n",
       "      <td>64.203110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.951809</td>\n",
       "      <td>66.532631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41.477543</td>\n",
       "      <td>51.996513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>46.286964</td>\n",
       "      <td>66.532631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48.562290</td>\n",
       "      <td>59.580853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>53.001152</td>\n",
       "      <td>53.583805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>51.288055</td>\n",
       "      <td>66.532631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Pred      Label\n",
       "0  41.543968  38.617382\n",
       "1  49.978638  35.326580\n",
       "2  45.009800  35.326580\n",
       "3  51.501141  64.203110\n",
       "4  48.951809  66.532631\n",
       "5  41.477543  51.996513\n",
       "6  46.286964  66.532631\n",
       "7  48.562290  59.580853\n",
       "8  53.001152  53.583805\n",
       "9  51.288055  66.532631"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 697457,
     "status": "ok",
     "timestamp": 1597834471988,
     "user": {
      "displayName": "Beerend Gerats",
      "photoUrl": "",
      "userId": "02409374618171011835"
     },
     "user_tz": -120
    },
    "id": "-ff06jtDZG07",
    "outputId": "4ca3698f-d47d-4c55-9709-213f616ad2e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 38.747214933641914\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(test_loader, model, mae, mse, epoch, opts)\n",
    "log_file.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_TReNDS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
